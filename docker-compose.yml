version: "3.8"

services:
  # Service Spacy
  spacy_service:
    image: spacy-service:latest
    build:
      context: ./Spacy
      dockerfile: Dockerfile
    container_name: spacy_container
    networks:
      - my_app_network
    ports:
      - "5003:5003"
    restart: unless-stopped
    environment:
      - FLASK_RUN_HOST=0.0.0.0
      - FLASK_RUN_PORT=5003

  # Service Scikit-learn-IF (Isolation Forest)
  sklearn-IF_service:
    image: sklearn-if-service:latest
    build:
      context: ./Sklearn-IF
      dockerfile: Dockerfile
    container_name: sklearn_if_container
    networks:
      - my_app_network
    ports:
      - "5001:5001"
    restart: unless-stopped
    environment:
      - FLASK_RUN_HOST=0.0.0.0
      - FLASK_RUN_PORT=5001
      - SPACY_API_URL=http://spacy_service:5003
    depends_on:
      - spacy_service

  # Service Scikit-learn-OCSVM (One-Class SVM)
  sklearn-OCSVM_service:
    image: sklearn-ocsvm-service:latest
    build:
      context: ./Sklearn-OCSVM
      dockerfile: Dockerfile
    container_name: sklearn_ocsvm_container
    networks:
      - my_app_network
    ports:
      - "6002:5002"
    restart: unless-stopped
    environment:
      - FLASK_RUN_HOST=0.0.0.0
      - FLASK_RUN_PORT=5002
      - SPACY_API_URL=http://spacy_service:5003
    depends_on:
      - spacy_service

  # Service Ollama
  ollama:
    image: ollama/ollama:latest
    container_name: ollama_container
    networks:
      - my_app_network
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0:11434
    restart: unless-stopped

  # Service d'initialisation Ollama
  ollama_init:
    image: curlimages/curl:latest
    container_name: ollama_init_container
    networks:
      - my_app_network
    depends_on:
      - ollama
    command: >
      sh -c "
        echo 'Attente du démarrage d Ollama...' &&
        sleep 60 &&
        echo 'Test de connexion à Ollama...' &&
        until curl -f http://ollama:11434/api/tags; do
          echo 'Ollama pas encore prêt, attente...'
          sleep 10
        done &&
        echo 'Ollama est prêt! Téléchargement du modèle qwen2:0.5b...' &&
        curl -X POST http://ollama:11434/api/pull -H 'Content-Type: application/json' -d '{\"name\": \"qwen2:0.5b\"}' &&
        echo 'Attente fin téléchargement...' &&
        sleep 120 &&
        echo 'Vérification modèle téléchargé:' &&
        curl http://ollama:11434/api/tags &&
        echo 'Initialisation terminée!'
      "
    restart: "no"

  # Service Chatbot LLM
  chatbot_web:
    image: chatbot-web:latest
    build:
      context: ./model_LLM
      dockerfile: Dockerfile
    container_name: chatbot_llm_container
    networks:
      - my_app_network
    ports:
      - "8000:8000"
    restart: unless-stopped
    environment:
      - OLLAMA_URL=http://ollama:11434
      - FLASK_RUN_HOST=0.0.0.0
      - FLASK_RUN_PORT=8000
      - SPACY_API_URL=http://spacy_service:5003
      - SKLEARN_API_URL_5001=http://sklearn-IF_service:5001
      - SKLEARN_API_URL_5002=http://sklearn-OCSVM_service:5002
    depends_on:
      - spacy_service
      - sklearn-IF_service
      - sklearn-OCSVM_service
      - ollama_init

  # Service Prometheus (avec volume de persistance)
  prometheus:
    image: prom/prometheus:latest
    container_name: my_prometheus
    networks:
      - my_app_network
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus # ✅ VOLUME POUR PERSISTANCE
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
    ports:
      - "6090:9090"
    restart: unless-stopped
    depends_on:
      - spacy_service
      - sklearn-IF_service
      - sklearn-OCSVM_service
      - chatbot_web

  # Service Grafana (avec volume de persistance)
  grafana:
    image: grafana/grafana:latest
    container_name: my_grafana
    networks:
      - my_app_network
    ports:
      - "6000:3000"
    volumes:
      - grafana-data:/var/lib/grafana # ✅ VOLUME POUR DASHBOARDS
    environment:
      # Configuration optionnelle pour éviter la perte des dashboards
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    restart: unless-stopped
    depends_on:
      - prometheus

  # ✅ Service Node Exporter pour métriques système
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node_exporter
    command:
      - "--path.rootfs=/host"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    networks:
      - my_app_network
    ports:
      - "9100:9100"
    volumes:
      - "/:/host:ro,rslave"
    restart: unless-stopped
    depends_on:
      - prometheus

# Définition des volumes Docker
volumes:
  ollama_data:
    driver: local
  grafana-data: # ✅ VOLUME POUR LES DASHBOARDS GRAFANA
    driver: local
  prometheus-data: # ✅ VOLUME POUR LES DONNÉES PROMETHEUS
    driver: local

# Définition du réseau Docker personnalisé
networks:
  my_app_network:
    driver: bridge
